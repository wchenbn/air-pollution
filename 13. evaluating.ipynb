{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab utils\n",
    "## *Don't forget to set GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/zafir/miniconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional, RepeatVector, Dot, Activation\n",
    "from tensorflow.keras.layers import Concatenate, Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "import pickle\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_folder_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'Miladinovci'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PretrainedModels = namedtuple('PretrainedModels', ['standard', 'attentive'])\n",
    "best_models = {\n",
    "    'Centar': PretrainedModels('2020-06-06-08-53-36', '2020-06-06-08-56-06'),\n",
    "    'Karpos': PretrainedModels('2020-06-06-09-06-42', '2020-06-06-09-08-54'),\n",
    "    'Lisice': PretrainedModels('2020-06-06-09-17-17', '2020-06-06-09-18-28'),\n",
    "    'Rektorat': PretrainedModels('2020-06-06-09-28-19', '2020-06-06-09-29-38'),\n",
    "    'Miladinovci': PretrainedModels('2020-06-05-17-52-45', '2020-06-05-17-55-40'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retransform_data(scaler, data):\n",
    "    data = scaler.inverse_transform(data)\n",
    "    data = np.exp(data) - 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./pickles/scalers/{sensor}/PM10', 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_input_data = np.load(f'./data/third-order/{sensor}/train_encoder_input_data.npy')\n",
    "train_decoder_input_data = np.load(f'./data/third-order/{sensor}/train_decoder_input_data.npy')\n",
    "train_decoder_target_data = np.load(f'./data/third-order/{sensor}/train_decoder_target_data.npy')\n",
    "\n",
    "valid_encoder_input_data = np.load(f'./data/third-order/{sensor}/valid_encoder_input_data.npy')\n",
    "valid_decoder_input_data = np.load(f'./data/third-order/{sensor}/valid_decoder_input_data.npy')\n",
    "valid_decoder_target_data = np.load(f'./data/third-order/{sensor}/valid_decoder_target_data.npy')\n",
    "\n",
    "test_encoder_input_data = np.load(f'./data/third-order/{sensor}/test_encoder_input_data.npy')\n",
    "test_decoder_input_data = np.load(f'./data/third-order/{sensor}/test_decoder_input_data.npy')\n",
    "test_decoder_target_data = np.load(f'./data/third-order/{sensor}/test_decoder_target_data.npy')\n",
    "test_decoder_target_data = test_decoder_target_data.flatten()\n",
    "y_true_retransformed = retransform_data(scaler, test_decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train, Tx, encoder_input_dim = train_encoder_input_data.shape\n",
    "    \n",
    "Ty, decoder_input_dim = (train_decoder_input_data.shape[1], \n",
    "                         train_decoder_input_data.shape[2])\n",
    "\n",
    "decoder_output_dim = train_decoder_target_data.shape[2]\n",
    "\n",
    "m_val = valid_encoder_input_data.shape[0]\n",
    "m_test = test_decoder_input_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Train Model\n",
    "\n",
    "First, using the best hyperparameters found during the random search, we fine tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "dense_dropout_rate = 0\n",
    "learning_rate = 0.000219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# ------------------- SHARED LAYERS ---------------------\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, \n",
    "                      name='encoder_lstm')\n",
    "decoder_lstm = LSTM(latent_dim, return_state=True, \n",
    "                    return_sequences=True, name='decoder_lstm')\n",
    "decoder_dense = Dense(decoder_output_dim, \n",
    "                      activation='linear', name='decoder_dense')\n",
    "dense_dropout = Dropout(rate=dense_dropout_rate, name='dense_dropout')\n",
    "\n",
    "# -------------------- TRAIN MODEL ----------------------\n",
    "encoder_inputs = Input(shape=(Tx, encoder_input_dim), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "decoder_inputs = Input(shape=(Ty, decoder_input_dim), \n",
    "                       name='decoder_inputs')\n",
    "\n",
    "# Obtain the hidden states of the encoder\n",
    "_, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# Obtain the outputs of the decoder (we disregard the hidden \n",
    "# states during training)\n",
    "x, _, _ = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "x = dense_dropout(x)\n",
    "decoder_outputs = decoder_dense(x)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "              outputs=decoder_outputs)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(f'Starting training at: {timestamp}')\n",
    "\n",
    "history = model.fit(x=[train_encoder_input_data, \n",
    "                       train_decoder_input_data], \n",
    "                    y=train_decoder_target_data,\n",
    "                    validation_data=([\n",
    "                       valid_encoder_input_data,\n",
    "                       valid_decoder_input_data],\n",
    "                       valid_decoder_target_data),\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    callbacks=[ModelCheckpoint(f'./checkpoints/{sensor}/standard/{timestamp}.h5', \n",
    "                                               save_best_only=True),\n",
    "                               EarlyStopping(monitor='val_loss', \n",
    "                                             patience=10, \n",
    "                                             verbose=1)])\n",
    "\n",
    "with open(f'./histories/{sensor}/standard/{timestamp}.pkl', 'wb') as output:\n",
    "    pickle.dump(history.history, output)\n",
    "    \n",
    "with open(f'./histories/{sensor}/standard/results.csv', 'a') as file:\n",
    "    min_epoch = np.argmin(history.history['val_loss'])\n",
    "    file.write(f\"{timestamp}, {min_epoch}, {history.history['loss'][min_epoch]}, {history.history['val_loss'][min_epoch]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./histories/{sensor}/standard/{timestamp}.pkl', 'rb') as inp:\n",
    "    history = pickle.load(inp)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Inference Model\n",
    "\n",
    "Now, load the best (trained) model, obtain the layers and build an inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = best_models[sensor].standard\n",
    "best_model = load_model(f'./checkpoints/{sensor}/standard/{timestamp}.h5')\n",
    "\n",
    "encoder_lstm = best_model.get_layer('encoder_lstm')\n",
    "decoder_lstm = best_model.get_layer('decoder_lstm')\n",
    "dense_dropout = best_model.get_layer('dense_dropout')\n",
    "decoder_dense = best_model.get_layer('decoder_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# ------------------ INFERENCE MODEL --------------------\n",
    "encoder_inputs = Input(shape=(Tx, encoder_input_dim), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "decoder_inputs = Input(shape=(Ty, decoder_input_dim), \n",
    "                       name='decoder_inputs')\n",
    "\n",
    "# Obtain the hidden states of the encoder\n",
    "_, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for t in range(Ty):\n",
    "    if t == 0:\n",
    "        x = Lambda(lambda z: z[:, t, :])(decoder_inputs)\n",
    "    else:\n",
    "        x = Lambda(lambda z: z[:, t, 1:])(decoder_inputs)\n",
    "        x = Concatenate(axis=-1)([out, x])\n",
    "    \n",
    "    decoder_input = Reshape((1, x.shape[1]))(x)\n",
    "    \n",
    "    # Obtain the output and hidden states of the decoder LSTM \n",
    "    out, h, c = decoder_lstm(decoder_input, initial_state=[h, c])\n",
    "    out = dense_dropout(out)\n",
    "    out = decoder_dense(out)\n",
    "    out = Flatten()(out)\n",
    "    outputs.append(out)\n",
    "\n",
    "inference_model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "              outputs=outputs, name='inference_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = inference_model.predict([test_encoder_input_data, test_decoder_input_data])\n",
    "y_pred = format_model_output(y_pred)\n",
    "y_pred_retransformed = retransform_data(scaler, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miladinovci\tArchitecture: standard\tRMSE: 40.64072036743164\tR^2: 0.23855493910746906\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(K.eval(tf.keras.losses.mean_squared_error(y_true_retransformed, \n",
    "                                                         y_pred_retransformed)))\n",
    "r2 = r2_score(y_true_retransformed, y_pred_retransformed)\n",
    "print(f'{sensor}\\tArchitecture: standard\\tRMSE: {rmse}\\tR^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentive Train Model\n",
    "\n",
    "First, using the best hyperparameters found during the random search, we fine tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(encoder_outputs, h_prev, attention_repeat, \n",
    "                       attention_concatenate, attention_dense_1,\n",
    "                       attention_dense_2, attention_activation,\n",
    "                       attention_dot):\n",
    "    \n",
    "    x = attention_repeat(h_prev)\n",
    "    x = attention_concatenate([encoder_outputs, x])\n",
    "    x = attention_dense_1(x)\n",
    "    energies = attention_dense_2(x)\n",
    "    alphas = attention_activation(energies)\n",
    "    context = attention_dot([alphas, encoder_outputs])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_attentive_model(encoder_latent_dim, decoder_latent_dim,\n",
    "                           attention_dense_dim, seq_dropout_rate,\n",
    "                           dense_dropout_rate, learning_rate):\n",
    "    K.clear_session()\n",
    "\n",
    "    # ------------------- SHARED LAYERS ---------------------\n",
    "    # Encoder layers\n",
    "    encoder_lstm = Bidirectional(LSTM(encoder_latent_dim, return_sequences=True, \n",
    "                                      name='encoder_lstm'), merge_mode='concat')\n",
    "\n",
    "    # Attention layers\n",
    "    attention_repeat = RepeatVector(n=Tx, name='attention_repeat')\n",
    "    attention_concatenate = Concatenate(axis=-1, name='attention_concatenate')\n",
    "    attention_dense_1 = Dense(attention_dense_dim, activation='tanh', \n",
    "                              name='attention_dense_1')\n",
    "    attention_dense_2 = Dense(1, activation='relu', name='attention_dense_2')\n",
    "    attention_activation = Activation(softmax, name='attention_activation') \n",
    "    attention_dot = Dot(axes=1, name='attention_dot')\n",
    "\n",
    "    # Decoder layers\n",
    "    decoder_concatenate = Concatenate(axis=-1, name='decoder_concatenate')\n",
    "    decoder_lstm = LSTM(decoder_latent_dim, return_state=True, \n",
    "                        name='decoder_lstm')\n",
    "    decoder_dense = Dense(decoder_output_dim, activation='linear',\n",
    "                          name='decoder_dense')\n",
    "\n",
    "    seq_dropout = Dropout(rate=seq_dropout_rate, name='seq_dropout')\n",
    "    dense_dropout = Dropout(rate=dense_dropout_rate, name='dense_dropout')\n",
    "\n",
    "    # -------------------- TRAIN MODEL ----------------------\n",
    "    encoder_inputs = Input(shape=(Tx, encoder_input_dim), \n",
    "                           name='encoder_inputs')\n",
    "    \n",
    "    decoder_inputs = Input(shape=(Ty, decoder_input_dim), \n",
    "                           name='decoder_inputs')\n",
    "\n",
    "    x = encoder_lstm(encoder_inputs)\n",
    "    encoder_outputs = seq_dropout(x)\n",
    "\n",
    "    h0 = Input(shape=(decoder_latent_dim,), name='h0')\n",
    "    c0 = Input(shape=(decoder_latent_dim,), name='c0')\n",
    "    h, c = h0, c0\n",
    "\n",
    "    # Decoder outputs\n",
    "    outputs = []\n",
    "\n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(encoder_outputs, h, attention_repeat, \n",
    "                                     attention_concatenate, attention_dense_1,\n",
    "                                     attention_dense_2, attention_activation,\n",
    "                                     attention_dot)\n",
    "\n",
    "        # Obtain the decoder input at timestamp t\n",
    "        x = Lambda(lambda z: z[:, t, :])(decoder_inputs)\n",
    "        decoder_input = Reshape((1, x.shape[1]))(x)\n",
    "\n",
    "        # Construct the full decoder input by concatenating the input at \n",
    "        # timestemp t with the calculated context\n",
    "        full_decoder_input = decoder_concatenate([decoder_input, context])\n",
    "\n",
    "        h, _, c = decoder_lstm(full_decoder_input, initial_state=[h, c])\n",
    "        x = dense_dropout(h)\n",
    "        decoder_output = decoder_dense(x)\n",
    "\n",
    "        outputs.append(decoder_output)\n",
    "\n",
    "    model = Model(inputs=[encoder_inputs, decoder_inputs, h0, c0], \n",
    "                  outputs=outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_latent_dim = 64\n",
    "decoder_latent_dim = 96\n",
    "attention_dense_dim = 12\n",
    "seq_dropout_rate = 0.4\n",
    "dense_dropout_rate = 0.2\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_train = np.zeros((m_train, decoder_latent_dim))\n",
    "c0_train = np.zeros((m_train, decoder_latent_dim))\n",
    "\n",
    "h0_val = np.zeros((m_val, decoder_latent_dim))\n",
    "c0_val = np.zeros((m_val, decoder_latent_dim))\n",
    "\n",
    "h0_test = np.zeros((m_test, decoder_latent_dim))\n",
    "c0_test = np.zeros((m_test, decoder_latent_dim))\n",
    "\n",
    "# due to the model architecture, we need to transform the output shape and type\n",
    "train_attentive_decoder_target_data = list(np.swapaxes(\n",
    "                                              train_decoder_target_data, 0, 1))\n",
    "valid_attentive_decoder_target_data = list(np.swapaxes(\n",
    "                                              valid_decoder_target_data, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_attentive_model(encoder_latent_dim, decoder_latent_dim,\n",
    "                               attention_dense_dim, seq_dropout_rate,\n",
    "                               dense_dropout_rate, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(f'Starting training at: {timestamp}')\n",
    "\n",
    "history = model.fit(x=[train_encoder_input_data, \n",
    "                       train_decoder_input_data,\n",
    "                       h0_train, c0_train], \n",
    "                    y=train_attentive_decoder_target_data,\n",
    "                    validation_data=([\n",
    "                       valid_encoder_input_data,\n",
    "                       valid_decoder_input_data, \n",
    "                       h0_val, c0_val],\n",
    "                       valid_attentive_decoder_target_data),\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    verbose=0,\n",
    "                    callbacks=[LossPrintingCallback(Ty),\n",
    "                               ModelCheckpoint(f'./checkpoints/{sensor}/attentive/{timestamp}/cpt',\n",
    "                                               save_weights_only=True,\n",
    "                                               save_best_only=True),\n",
    "                               EarlyStopping(monitor='val_loss', \n",
    "                                             patience=10, \n",
    "                                             verbose=1)])\n",
    "\n",
    "with open(f'./histories/{sensor}/attentive/{timestamp}.pkl', 'wb') as output:\n",
    "    pickle.dump(history.history, output)\n",
    "    \n",
    "with open(f'./histories/{sensor}/attentive/results.csv', 'a') as file:\n",
    "    min_epoch = np.argmin(history.history['val_loss'])\n",
    "    file.write(f\"{timestamp}, {min_epoch}, {history.history['loss'][min_epoch]}, {history.history['val_loss'][min_epoch]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./histories/{sensor}/attentive/{timestamp}.pkl', 'rb') as inp:\n",
    "    history = pickle.load(inp)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentive Inference Model\n",
    "\n",
    "Now, load the best (trained) model, obtain the layers and build an inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = best_models[sensor].attentive\n",
    "\n",
    "best_model = create_attentive_model(encoder_latent_dim, decoder_latent_dim,\n",
    "                               attention_dense_dim, seq_dropout_rate,\n",
    "                               dense_dropout_rate, learning_rate)\n",
    "\n",
    "best_model.load_weights(f'./checkpoints/{sensor}/attentive/{timestamp}/cpt')\n",
    "\n",
    "# ----------------- PRETRAINED LAYERS -------------------\n",
    "# Encoder layers\n",
    "encoder_lstm = best_model.get_layer('bidirectional')\n",
    "\n",
    "# Attention layers\n",
    "attention_repeat = best_model.get_layer('attention_repeat')\n",
    "attention_concatenate = best_model.get_layer('attention_concatenate')\n",
    "attention_dense_1 = best_model.get_layer('attention_dense_1')\n",
    "attention_dense_2 = best_model.get_layer('attention_dense_2')\n",
    "attention_activation = best_model.get_layer('attention_activation')\n",
    "attention_dot = best_model.get_layer('attention_dot')\n",
    "\n",
    "# Decoder layers\n",
    "decoder_concatenate = best_model.get_layer('decoder_concatenate')\n",
    "decoder_lstm = best_model.get_layer('decoder_lstm')\n",
    "decoder_dense = best_model.get_layer('decoder_dense')\n",
    "\n",
    "seq_dropout = best_model.get_layer('seq_dropout')\n",
    "dense_dropout = best_model.get_layer('dense_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# ------------------ INFERENCE MODEL --------------------\n",
    "encoder_inputs = Input(shape=(Tx, encoder_input_dim), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "decoder_inputs = Input(shape=(Ty, decoder_input_dim), \n",
    "                       name='decoder_inputs')\n",
    "\n",
    "x = encoder_lstm(encoder_inputs)\n",
    "encoder_outputs = seq_dropout(x)\n",
    "\n",
    "h0 = Input(shape=(decoder_latent_dim,), name='h0')\n",
    "c0 = Input(shape=(decoder_latent_dim,), name='c0')\n",
    "h, c = h0, c0\n",
    "\n",
    "# Decoder outputs\n",
    "outputs = []\n",
    "\n",
    "for t in range(Ty):\n",
    "    context = one_step_attention(encoder_outputs, h, attention_repeat, \n",
    "                                 attention_concatenate, attention_dense_1,\n",
    "                                 attention_dense_2, attention_activation,\n",
    "                                 attention_dot)\n",
    "    \n",
    "    # Obtain the decoder input at timestamp t. If it's the first timestep,\n",
    "    # consider all of the features, otherwise use the calculated PM value\n",
    "    # in the previous timestep.\n",
    "    if t == 0:\n",
    "        x = Lambda(lambda z: z[:, t, :])(decoder_inputs)\n",
    "    else:\n",
    "        x = Lambda(lambda z: z[:, t, 1:])(decoder_inputs)\n",
    "        x = Concatenate(axis=-1)([decoder_output, x])\n",
    "    \n",
    "    decoder_input = Reshape((1, x.shape[1]))(x)\n",
    "\n",
    "    # Construct the full decoder input by concatenating the input at \n",
    "    # timestemp t with the calculated context\n",
    "    full_decoder_input = decoder_concatenate([decoder_input, context])\n",
    "\n",
    "    h, _, c = decoder_lstm(full_decoder_input, initial_state=[h, c])\n",
    "    x = dense_dropout(h)\n",
    "    decoder_output = decoder_dense(x)\n",
    "    outputs.append(decoder_output)\n",
    "\n",
    "inference_model = Model(inputs=[encoder_inputs, decoder_inputs, h0, c0], \n",
    "                        outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = inference_model.predict([test_encoder_input_data, test_decoder_input_data,\n",
    "                                  h0_test, c0_test])\n",
    "y_pred = format_model_output(y_pred)\n",
    "y_pred_retransformed = retransform_data(scaler, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miladinovci\tArchitecture: attentive\tRMSE: 32.90631866455078\tR^2: 0.5008003717648755\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(K.eval(tf.keras.losses.mean_squared_error(y_true_retransformed, \n",
    "                                                         y_pred_retransformed)))\n",
    "r2 = r2_score(y_true_retransformed, y_pred_retransformed)\n",
    "print(f'{sensor}\\tArchitecture: attentive\\tRMSE: {rmse}\\tR^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
